# installs tempo
---
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: tempo-distributed-appset
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "2"
spec:
  goTemplate: true
  # generator allows us to source specific values from an external secret
  generators:
    - plugin:
        configMapRef:
          name: secret-var-plugin-generator
        input:
          parameters:
            secret_vars:
              - tempo_stack_tempo_hostname
              - global_cluster_issuer
  template:
    metadata:
      name: tempo-distributed
    spec:
      project: monitoring
      syncPolicy:
        syncOptions:
          - ApplyOutOfSyncOnly=true
        automated:
          selfHeal: true
          prune: true

      # where to deploy this application
      destination:
        server: https://kubernetes.default.svc
        namespace: monitoring

      # where to source this application from
      source:
        repoURL: https://grafana.github.io/helm-charts
        # https://github.com/grafana/helm-charts/tree/main/charts/tempo-distributed
        chart: tempo-distributed
        targetRevision: 1.46.3
        helm:
          releaseName: tempo
          valuesObject:
            fullnameOverride: tempo

            # -- Configuration is loaded from the secret called 'externalConfigSecretName'.
            # If 'useExternalConfig' is true, then the configuration is not generated, just
            # consumed.  Top level keys for `tempo.yaml` and `overrides.yaml` are to be
            # provided by the user.
            useExternalConfig: true

            # -- Defines what kind of object stores the configuration, a ConfigMap or a Secret.
            # In order to move sensitive information (such as credentials) from the ConfigMap/Secret to a more secure location (e.g. vault), it is possible to use [environment variables in the configuration](https://grafana.com/docs/mimir/latest/operators-guide/configuring/reference-configuration-parameters/#use-environment-variables-in-the-configuration).
            # Such environment variables can be then stored in a separate Secret and injected via the global.extraEnvFrom value. For details about environment injection from a Secret please see [Secrets](https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables).
            configStorageType: Secret

            # -- Name of the Secret or ConfigMap that contains the configuration (used for naming even if config is internal).
            externalConfigSecretName: tempo-config

            # -- Name of the Secret or ConfigMap that contains the runtime configuration (used for naming even if config is internal).
            externalRuntimeConfigName: tempo-runtime-config

            # -- When 'useExternalConfig' is true, then changing
            # 'externalConfigVersion' triggers restart of services - otherwise
            # changes to the configuration cause a restart.
            externalConfigVersion: '0'

            # If true, Tempo will report anonymous usage data about the shape of
            # a deployment to Grafana Labs
            reportingEnabled: false

            global:
              # need this to expand env variables in configs
              extraArgs:
                - -config.expand-env=true

              extraEnv:
                # we need this for the memberlist ring sync thing
                - name: MY_POD_IP
                  valueFrom:
                    fieldRef:
                      fieldPath: status.podIP

                # we need this for valkey
                - name: VALKEY_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      # TODO: change this to tempo later
                      name: tempo-valkey-credentials
                      key: password

                - name: S3_HOSTNAME
                  valueFrom:
                    secretKeyRef:
                      name: s3-tempo-credentials
                      key: S3_HOSTNAME

                - name: S3_BUCKET
                  valueFrom:
                    secretKeyRef:
                      name: s3-tempo-credentials
                      key: S3_BUCKET

                - name: S3_USER
                  valueFrom:
                    secretKeyRef:
                      name: s3-tempo-credentials
                      key: S3_USER

                - name: S3_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: s3-tempo-credentials
                      key: S3_PASSWORD

            # Configuration for the ingester
            ingester:
              # -- Number of replicas for the ingester
              replicas: 1
              autoscaling:
                # -- Enable autoscaling for the ingester.
                # WARNING: Autoscaling ingesters can result in lost data.
                # Only do this if you know what you're doing.
                enabled: false
                # -- Minimum autoscaling replicas for the ingester
                minReplicas: 2
                # -- Maximum autoscaling replicas for the ingester
                maxReplicas: 3
                # -- Autoscaling behavior configuration for the ingester
                behavior: {}
                # -- Target CPU utilisation percentage for the ingester
                targetCPUUtilizationPercentage: 60
                # -- Target memory utilisation percentage for the ingester
                targetMemoryUtilizationPercentage:
              extraArgs:
                - -config.expand-env=true

            # Configuration for the metrics-generator
            metricsGenerator:
              # -- Specifies whether a metrics-generator should be deployed
              enabled: false
              # -- Kind of deployment [StatefulSet/Deployment]
              kind: Deployment
              # -- Annotations for the metrics-generator StatefulSet
              annotations: {}
              # -- Number of replicas for the metrics-generator
              replicas: 1

            # Configuration for the distributor
            distributor:
              # -- Number of replicas for the distributor
              replicas: 1
              autoscaling:
                # -- Enable autoscaling for the distributor
                enabled: false
                # -- Minimum autoscaling replicas for the distributor
                minReplicas: 1
                # -- Maximum autoscaling replicas for the distributor
                maxReplicas: 3
                # -- Autoscaling behavior configuration for the distributor
                behavior: {}
                # -- Target CPU utilisation percentage for the distributor
                targetCPUUtilizationPercentage: 60
                # -- Target memory utilisation percentage for the distributor
                targetMemoryUtilizationPercentage:
              extraArgs:
                - -config.expand-env=true

            # Configuration for the compactor
            compactor:
              extraArgs:
                - -config.expand-env=true
              # -- Number of replicas for the compactor
              replicas: 1
              # -- Autoscaling configurations
              autoscaling:
                # -- Enable autoscaling for the compactor
                enabled: false
                # -- Minimum autoscaling replicas for the compactor
                minReplicas: 1
                # -- Maximum autoscaling replicas for the compactor
                maxReplicas: 3
                # -- Autoscaling via HPA object
                hpa:
                  enabled: false
                  # -- Autoscaling behavior configuration for the compactor
                  behavior: {}
                  # -- Target CPU utilisation percentage for the compactor
                  targetCPUUtilizationPercentage: 100
                  # -- Target memory utilisation percentage for the compactor
                  targetMemoryUtilizationPercentage:
                # -- Autoscaling via keda/ScaledObject
                keda:
                  # requires https://keda.sh/
                  enabled: false
                config:
                  compaction:
                    # -- Duration to keep blocks
                    block_retention: 48h
                    # Duration to keep blocks that have been compacted elsewhere
                    compacted_block_retention: 1h
                    # -- Blocks in this time window will be compacted together
                    compaction_window: 1h
                    # -- Amount of data to buffer from input blocks
                    v2_in_buffer_bytes: 5242880
                    # -- Flush data to backend when buffer is this large
                    v2_out_buffer_bytes: 20971520
                    # -- Maximum size of a compacted block in bytes
                    max_block_bytes: 107374182400
                    # -- Number of tenants to process in parallel during retention
                    retention_concurrency: 10
                    # -- Number of traces to buffer in memory during compaction
                    v2_prefetch_traces_count: 1000
                    # -- The maximum amount of time to spend compacting a single tenant before moving to the next
                    max_time_per_tenant: 5m
                    # -- The time between compaction cycles
                    compaction_cycle: 30s


            # Configuration for the querier
            querier:
              extraArgs:
                - -config.expand-env=true
              # -- Number of replicas for the querier
              replicas: 1
              autoscaling:
                # -- Enable autoscaling for the querier
                enabled: false
                # -- Minimum autoscaling replicas for the querier
                minReplicas: 1
                # -- Maximum autoscaling replicas for the querier
                maxReplicas: 3
                # -- Autoscaling behavior configuration for the querier
                behavior: {}
                # -- Target CPU utilisation percentage for the querier
                targetCPUUtilizationPercentage: 60
                # -- Target memory utilisation percentage for the querier
                targetMemoryUtilizationPercentage:

            # Configuration for the query-frontend
            queryFrontend:
              # -- Number of replicas for the query-frontend
              replicas: 1
              extraArgs:
                - -config.expand-env=true

            traces:
              jaeger:
                grpc:
                  # -- Enable Tempo to ingest Jaeger GRPC traces
                  enabled: false
                  # -- Jaeger GRPC receiver config
                  receiverConfig: {}
                thriftBinary:
                  # -- Enable Tempo to ingest Jaeger Thrift Binary traces
                  enabled: false
                  # -- Jaeger Thrift Binary receiver config
                  receiverConfig: {}
                thriftCompact:
                  # -- Enable Tempo to ingest Jaeger Thrift Compact traces
                  enabled: false
                  # -- Jaeger Thrift Compact receiver config
                  receiverConfig: {}
                thriftHttp:
                  # -- Enable Tempo to ingest Jaeger Thrift HTTP traces
                  enabled: false
                  # -- Jaeger Thrift HTTP receiver config
                  receiverConfig: {}
              zipkin:
                # -- Enable Tempo to ingest Zipkin traces
                enabled: false
                # -- Zipkin receiver config
                receiverConfig: {}
              otlp:
                http:
                  # -- Enable Tempo to ingest Open Telemetry HTTP traces
                  enabled: true
                  # -- HTTP receiver advanced config
                  receiverConfig: {}
                grpc:
                  # -- Enable Tempo to ingest Open Telemetry GRPC traces
                  enabled: true
                  # -- GRPC receiver advanced config
                  receiverConfig: {}
                  # -- Default OTLP gRPC port
                  port: 4317
              opencensus:
                # -- Enable Tempo to ingest Open Census traces
                enabled: false
                # -- Open Census receiver config
                receiverConfig: {}
              # -- Enable Tempo to ingest traces from Kafka. Reference: https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/kafkareceiver
              kafka: {}

            # -- Memberlist configuration. Please refer to:
            # https://grafana.com/docs/tempo/latest/configuration/#memberlist
            memberlist:
              node_name: ""
              cluster_label: "tempo.monitoring"
              randomize_node_name: true
              stream_timeout: "10s"
              retransmit_factor: 2
              pull_push_interval: "30s"
              gossip_interval: "1s"
              gossip_nodes: 2
              gossip_to_dead_nodes_time: "30s"
              min_join_backoff: "1s"
              max_join_backoff: "1m"
              max_join_retries: 10
              abort_if_cluster_join_fails: false
              rejoin_interval: "0s"
              left_ingesters_timeout: "5m"
              leave_timeout: "5s"
              bind_addr:
                - ${MY_POD_IP}
              bind_port: 7946
              packet_dial_timeout: "5s"
              packet_write_timeout: "5s"

            # Set Tempo server configuration
            # Refers to https://grafana.com/docs/tempo/latest/configuration/#server
            server:
              # --  HTTP server listen host
              httpListenPort: 3200
              # -- Log level. Can be set to debug, info (default), warn, error
              logLevel: info
              # -- Log format. Can be set to logfmt (default) or json.
              logFormat: logfmt
              # -- Max gRPC message size that can be received
              grpc_server_max_recv_msg_size: 4194304
              # -- Max gRPC message size that can be sent
              grpc_server_max_send_msg_size: 4194304
              # -- Read timeout for HTTP server
              http_server_read_timeout: 30s
              # -- Write timeout for HTTP server
              http_server_write_timeout: 30s

            # Use this block to configure caches available throughout the application.
            # Multiple caches can be created and assigned roles which determine how they are used by Tempo.
            # https://grafana.com/docs/tempo/latest/configuration/#cache
            cache:
              caches:
                - roles:
                    - frontend-search
                  redis:
                    # Redis endpoint to use when caching.
                    endpoint: tempo-valkey-headless.monitoring.svc:6379

                    # optional.
                    # Maximum time to wait before giving up on redis requests. (default 100ms)
                    timeout: 500ms

                    # optional.
                    # How long keys stay in the redis. (default 0)
                    expiration: 0

                    # optional.
                    # Password to use when connecting to redis. (default "")
                    password: ${VALKEY_PASSWORD}

            storage:
              trace:
                # Settings for the block storage backend and buckets.
                block:
                  # supported block versions are specified here https://grafana.com/docs/tempo/latest/configuration/parquet/
                  version: null
                  # Lis with dedicated attribute columns (only for vParquet3 or later)
                  dedicated_columns: []
                # storage backends specified in https://grafana.com/docs/tempo/latest/configuration/#storage
                backend: s3

                # The worker pool is used primarily when finding traces by id, but is also used by others.
                pool:
                  # -- Total number of workers pulling jobs from the queue
                  max_workers: 400
                  # -- Length of job queue. imporatant for querier as it queues a job for every block it has to search
                  queue_depth: 20000
                # The supported search are specified here https://grafana.com/docs/tempo/latest/configuration/#search-config
                search:
                  # -- Number of traces to prefetch while scanning blocks. Increasing this value can improve trace search performance at the cost of memory.
                  prefetch_trace_count: 1000
                # -- How often to repoll the backend for new blocks
                blocklist_poll: 5m
                # -- Number of blocks to process in parallel during polling.
                blocklist_poll_concurrency: null
                # -- By default components will pull the blocklist from the tenant index. If that fails the component can
                # -- fallback to scanning the entire bucket. Set to false to disable this behavior.
                blocklist_poll_fallback: null
                # -- Maximum number of compactors that should build the tenant index. All other components will download the index.
                blocklist_poll_tenant_index_builders: null
                # -- The oldest allowable tenant index.
                blocklist_poll_stale_tenant_index: null
              # Settings for the Admin client storage backend and buckets. Only valid is enterprise.enabled is true.
              admin:
                # -- The supported storage backends are gcs, s3 and azure, as specified in https://grafana.com/docs/enterprise-traces/latest/configure/reference/#admin_client_config
                backend: filesystem

            # memcached is for all of the Tempo pieces to coordinate with each other.
            # you can use your self memcacherd by set enable: false and host + service
            memcached:
              # -- Specified whether the memcached cachce should be enabled
              enabled: false
              host: memcached
              # Number of replicas for memchached
              replicas: 1

            memcachedExporter:
              # -- Specifies whether the Memcached Exporter should be enabled
              enabled: false


            # Configuration for the gateway
            gateway:
              # -- Specifies whether the gateway should be enabled
              enabled: true
              # -- Number of replicas for the gateway
              replicas: 1
              autoscaling:
                # -- Enable autoscaling for the gateway
                enabled: false
                # -- Minimum autoscaling replicas for the gateway
                minReplicas: 1
                # -- Maximum autoscaling replicas for the gateway
                maxReplicas: 3
                # -- Autoscaling behavior configuration for the gateway
                behavior: {}
                # -- Target CPU utilisation percentage for the gateway
                targetCPUUtilizationPercentage: 60
                # -- Target memory utilisation percentage for the gateway
                targetMemoryUtilizationPercentage:

            # Settings for the initial admin(istrator) token generator job. Can only be enabled if
            # enterprise.enabled is true - requires license.
            tokengenJob:
              enable: false

            provisioner:
              # -- Whether the job should be part of the deployment
              enabled: false
              # -- Name of the secret to store provisioned tokens in
              provisionedSecretPrefix: null
              # -- Hook type(s) to customize when the job runs.  defaults to post-install
              hookType: "post-install"

            # Can only be enabled if enterprise.enabled is true - requires license.
            adminApi:
              replicas: 0
